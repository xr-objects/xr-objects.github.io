<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects.">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.dogadogan.com/">Mustafa Doga Dogan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.ejgonzalez.me/">Eric J. Gonzalez</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/andrea-colaco-612bb7a">Andrea Colaco</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://karan-ahuja.com/">Karan Ahuja</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://duruofei.com/">Ruofei Du</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://research.google/people/johnny-chung-lee/">Johnny Lee</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://margonzalezfranco.github.io/">Mar Gonzalez-Franco</a>*<sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://davidkim.de/">David Kim</a>*<sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Google</span>
            <br/>
            <span class="author-block"><sup>2</sup> Massachusetts Institute of Technology</span>
            <br/>
            <span class="author-block"><sup>*</sup>co-senior authorship</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/xr-objects"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
           
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

 <!-- Abstract. -->
 <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        Seamless integration of physical objects as interactive digital entities remains a challenge for spatial computing. 
        This paper introduces <span class="dnerf">Augmented Object Intelligence</span> (AOI), a novel XR interaction paradigm designed 
        to blur the lines between digital and physical by endowing real-world objects with the ability to interact as if they were digital,
         where every object has the potential to serve as a portal to vast digital functionalities.
        Our approach utilizes object segmentation and classification, combined with the power of Multimodal Large Language Models (MLLMs), 
        to facilitate these interactions.
        We implement the AOI concept in the form of <span class="dnerf">XR-Objects</span>, an open-source prototype system that provides a platform for users to 
        engage with their physical environment in rich and contextually relevant ways.
        This system enables analog objects to not only convey information but also to initiate digital actions, such as querying for 
        details or executing tasks.
        Our contributions are threefold: (1) we define the AOI concept and detail its advantages over traditional AI assistants, 
        (2) detail the <span class="dnerf">XR-Objects</span> system's open-source design and implementation, and 
        (3) show its versatility through a variety of use cases and a user study.
        
      </p>
     
    </div>
  </div>
</div>
<!--/ Abstract. -->



<section class="section">
  <!-- Paper video. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths" >
      <h2 class="title is-3">Video</h2>
     
        <video id="teaser" autoplay loop playsinline controls height="300px">
          <source src="./static/videos/XR-Objects.mp4"
                  type="video/mp4">
        </video>
   
    </div>
  </div>
  <!--/ Paper video. -->

</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <h2 class="title is-3">Applications</h2>
            <img src="https://github.com/google/xr-objects/raw/main/docs/FigureXRObjects.jpg"
        class="interpolation-image" width="100%"/>
        </div>
            <p> <img  style="float: left;padding-right: 30px;" src="./static/images/applications.png"
              width="225px"/>Through AOI, we envision XR-Objects to be useful across a variety of real-world applications. 
              By enabling in situ digital interactions with non-instrumented analog objects, we can expand their utility 
              (e.g., enabling a pot to double as a cooking timer), better synthesize their relevant information 
              (e.g., comparing nutritional value), and overall enable richer interactivity and flexibility in everyday interactions. 
                Here we present five example application scenarios from a broad application space we envision that highlight the value 
                of XR-Objects.</p><br/>
          </div>
        </div>
      </div>  
    </div>
        
      <br/>
        <div id="results-carousel" class="carousel results-carousel" style="border-width:0px;">
         
          <div class="item item-steve" style="border-width:0px;">
            <div class="columns is-centered" style="border-width:0px;">
            <img poster="" id="steve"  src="./static/images/discover.png"
            width="70%"/>
          </div>
          </div>
          
          <div class="item item-shiba" style="border-width:0px;">
            <div class="columns is-centered" style="border-width:0px;">
              
            <img poster="" id="shiba" src="./static/images/productivity.png"
            width="80%">
          </div>
          </div>
          <div class="item item-chair-tp" style="border-width:0px;">
            <div class="item" style="border-width:0px;">
              <img poster="" id="chair-tp"  src="./static/images/learning.png"
              width="90%">
            </div>
          </div>
          <div class="item item-fullbody" style="border-width:0px;">
            <img poster="" id="fullbody" src="./static/images/IOT.png"
            width="95%">
          </div>      
        </div>
        <br/>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">XR-Objects</span> makes analog objects interactable like if they were digital.
        </h2>
      
  </div>
 
</div>
</section>


<section class="section">
  
  <div class="container is-max-desktop">
    <!-- Concurrent Work.  -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Implementation</h2>

        <div class="content has-text-justified">
          
          <p>
            XR-Objects  leverages developments in spatial understanding via tools such as  SLAM, 
            available in <a
            href="https://developers.google.com/ar">Google ARCore </a> and 
            <a href="https://developer.apple.com/augmented-reality/arkit">Apple ARKit</a>, 
            and machine learning models for object segmentation and classification (<a href="https://cocodataset.org/COCO">COCO</a> 
            via <a href="https://developers.google.com/mediapipe">MediaPipe</a>), that enable us to implement AR interactions 
            with semantic depth.
            We also integrate a Multimodal Large Language Model (MLLM), 
            <a href="https://deepmind.google/technologies/gemini/">Google Gemini</a>, into our system, 
            which further enhances our ability to automate the recognition of objects and their specific 
            semantic information within XR spaces.  
          </p>
        
          <img poster="" id="fullbody" src="./static/images/pipeline_new.png">
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">

  

  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Dogan24XRobjects,
    author  = {Dogan, Mustafa Doga and Gonzalez, Eric J and Colaco, Andrea and Ahuja, Karan and Du, Ruofei and Lee, Johnny 
    and Gonzalez-Franco, Mar and Kim, David},
    title   = {Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects},
    journal = {arxiv},
    year    = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built on top of the original<a
            href="https://github.com/nerfies/nerfies.github.io">  Nerfies, <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 </a> International License.
          </p>
          </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
